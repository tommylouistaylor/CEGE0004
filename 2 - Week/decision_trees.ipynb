{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tommylouistaylor/CEGE0004_MachineLearning/blob/master/2%20-%20Week/decision_trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Trees\n",
        "\n",
        "In this notebook you will learn how to implement the **ID3 decision tree learner**, reproduce the results presented in the\n",
        "lecture, and learn how to **use the decision tree learners** of a popular machine learning module, scikit-learn."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Y3jkWppK00Ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Dataset For Learning Task\n",
        "\n",
        "Define a toy-dataset for the **PlayTennis learning task**; comprising features {att, cond}, examples (xs), targets (ys)"
      ],
      "metadata": {
        "id": "nqEXJIZbiU5p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": [
        "# FEATURES    ... dictionary containing attribute (key) and value (#)\n",
        "features = {\n",
        "    # keys=attribute  : values=possible conditions\n",
        "    ('outlook', 0)    : {'sunny', 'overcast', 'rain'},\n",
        "    ('temperature', 1): {'hot', 'mild', 'cool'},\n",
        "    ('humidity', 2)   : {'high', 'normal', 'low'},\n",
        "    ('wind', 3)       : {'weak', 'strong'}}\n",
        "\n",
        "# INPUT FEATURE EXAMPLES (xs)    ... list of all possible 'examples' aka combinations\n",
        "xs = [['sunny', 'hot', 'high', 'weak'],\n",
        "      ['sunny', 'hot', 'high', 'strong'],\n",
        "      ['overcast', 'hot', 'high', 'weak'],\n",
        "      ['rain', 'mild', 'high', 'weak'],\n",
        "      ['rain', 'cool', 'normal', 'weak'],\n",
        "      ['rain', 'cool', 'normal', 'strong'],\n",
        "      ['overcast', 'cool', 'normal', 'strong'],\n",
        "      ['sunny', 'mild', 'high', 'weak'],\n",
        "      ['sunny', 'cool', 'high', 'weak'],\n",
        "      ['rain', 'mild', 'normal', 'weak'],\n",
        "      ['sunny', 'mild', 'normal', 'strong'],\n",
        "      ['overcast', 'mild', 'high', 'strong'],\n",
        "      ['overcast', 'hot', 'normal', 'weak'],\n",
        "      ['rain', 'mild', 'high', 'strong']]\n",
        "\n",
        "# OUTPUT TARGET CLASS (ys)      ... list of corresponding target values\n",
        "ys = ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zMgMUrqz00K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opt2: Implement Manual DT Algorithm"
      ],
      "metadata": {
        "id": "omgZ_lVAO6tM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Tree Structure using Node Class"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zz0ZvYBl00K2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "oxN_5u8Y00K2"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "\n",
        "    # method1: create new instance of the class\n",
        "    def __init__(self):\n",
        "        self.feature = None \n",
        "        self.children = {}\n",
        "        self.label = None\n",
        "\n",
        "    # method2: check if the node is leaf (end)\n",
        "    def is_leaf(self):\n",
        "        return self.label is not None\n",
        "\n",
        "    # method3: check if node is decision/predict node (middle)\n",
        "    def predict(self, x):\n",
        "        if self.is_leaf():\n",
        "            return self.label\n",
        "        else:\n",
        "            feature_i = self.feature[1]\n",
        "            return self.children[x[feature_i]].predict(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct a Decision Tree"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Bef6gkWV00K3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "source": [
        "# create 'no' instance of Node() class where label = 'no\n",
        "no = Node()\n",
        "no.label = 'no'\n",
        "\n",
        "# create 'yes' instance of Node() class where label = 'yes'\n",
        "yes = Node()\n",
        "yes .label = 'yes'\n",
        "\n",
        "# create 'humidity' instance of Node() where ...\n",
        "humidity = Node()\n",
        "humidity.feature = ('humidity', 2)  # set as humidity key\n",
        "humidity.children['high'] = no\n",
        "humidity.children['normal'] = yes\n",
        "\n",
        "# create 'wind' instance of Node() where ...\n",
        "wind = Node()\n",
        "wind.feature = ('wind', 3)\n",
        "wind.children['strong'] = no\n",
        "wind.children['weak'] = yes\n",
        "\n",
        "# create 'wind' instance of Node() where ...\n",
        "outlook = Node()\n",
        "outlook.feature = ('outlook', 0)\n",
        "outlook.children['sunny'] = humidity\n",
        "outlook.children['overcast'] = yes\n",
        "outlook.children['rain'] = wind\n",
        "\n",
        "play_tennis = outlook"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LQXbfRaW00K4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show Decision Tree (Textual Form)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zGqybStc00K4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# function to show tree as text\n",
        "def show(node, skip = ''):\n",
        "    if node.feature:\n",
        "        print(skip, node.feature[0] + ':')\n",
        "    else:\n",
        "        print(skip, '->', node.label)\n",
        "    for value, node in node.children.items():\n",
        "        print(skip, '->', value)\n",
        "        show(node, skip + '  ')\n",
        "\n",
        "# call show function\n",
        "show(play_tennis)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7R2lbmXU00K5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Class for a given Example using DT Learner (Y=Play, N=Don't Play)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8LSSNW3N00K6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# pass example values into predict method (ordered as per features dict)\n",
        "play_tennis.predict(['sunny', 'hot', 'normal', 'weak']) # passing feature examples"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G685sbbC00K7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opt2: Implement ID3 DT Algorithm"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "F30WJIPA00K7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement function to randomly select feature"
      ],
      "metadata": {
        "id": "QSsB6ZBUPnNA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# define function to select a random feature\n",
        "def select_best_feature(xs, ys, features):              # pass the input examples and output classes\n",
        "    return random.choice(list(features.keys()))         # return random feature key. Always returns different key."
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pbNyhu3I00K8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# test function to select a random feature\n",
        "random_feature = select_best_feature(xs, ys, features)  # pass our examples list, classes list and features dictionary\n",
        "random_feature                                          # returns random key from features dictionary e.g. ('wind', 3)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "usWcLbYN00K9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement Function to partition data by feature and feature value"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "HbUxS5wi00K9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "source": [
        "# define function to select examples by feature arguments \n",
        "def select_data(xs, ys, feature, value):\n",
        "    xs_value = []\n",
        "    ys_value = []\n",
        "    for x, y in zip(xs, ys):\n",
        "        if x[feature[1]] == value:                      # if feature key  == specified feature key, append\n",
        "            xs_value.append(x)\n",
        "            ys_value.append(y)\n",
        "    return xs_value, ys_value"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "EYIiYHZ600K-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# test function to select examples by feature arguments\n",
        "select_data(xs, ys, ('temperature', 1), 'hot')          # pass examples (xs), classes (ys), feature key ('temperature', 1), value (hot)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "r4snXyoo00K-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement Function to remove one key from features dictionary"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Wed_6TPC00K_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": [
        "# define function to remove one feature key\n",
        "def dict_minus(dict, key):\n",
        "    dict = dict.copy()\n",
        "    dict.pop(key)\n",
        "    return dict"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "I-nZZy1k00K_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create test dictionary\n",
        "example_dict = {'feature_key_1': 'feature_val_1', \n",
        "                'feature_key_2': 'feature_val_2', \n",
        "                'feature_key_3': 'feature_val_3'}\n",
        "\n",
        "# pass test dictionary to function to remove one key\n",
        "dict_minus(example_dict, 'feature_key_2') # remove 'feature_key_2'"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yhSnU0fO00K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement the ID3 learning algorithm"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "i3OgFd-n00LA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "source": [
        "from statistics import mode\n",
        "\n",
        "# implement ID3 Learner\n",
        "def id3(xs, ys, features):\n",
        "    root = Node()\n",
        "    if all([y == 'yes' for y in ys]): root.label = 'yes'\n",
        "    elif all([y == 'no' for y in ys]): root.label = 'no'\n",
        "    elif not features: root.label = mode(ys)\n",
        "    else:\n",
        "        feature = select_best_feature(xs, ys, features)\n",
        "        root.feature = feature\n",
        "        for value in features[feature]:\n",
        "            node = Node()\n",
        "            root.children[value] = node\n",
        "            xs_value, ys_value = select_data(xs, ys, feature, value)\n",
        "            if not xs_value: node.label = mode(ys)\n",
        "            else: root.children[value] = \\\n",
        "                id3(xs_value, ys_value, dict_minus(features, feature))\n",
        "    return root"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "psRQD8eb00LA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To learn a decision tree based on the training set we will just need to invoke this function with the right parameters.\n",
        "\n",
        "Remember that we are now using an unusual `select_best_feature` (it picks an attribute at random). Will the\n",
        "learning algorithm output a decision tree that fits the training data?"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "SlHLXstc00LB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StatisticsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStatisticsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-62b0f6654aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtree_ran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_ran\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c6d0efb6a25d>\u001b[0m in \u001b[0;36mid3\u001b[0;34m(xs, ys, features)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mxs_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxs_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m                 \u001b[0mid3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_minus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-c6d0efb6a25d>\u001b[0m in \u001b[0;36mid3\u001b[0;34m(xs, ys, features)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mxs_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxs_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m                 \u001b[0mid3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_minus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/statistics.py\u001b[0m in \u001b[0;36mmode\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         raise StatisticsError(\n\u001b[0;32m--> 506\u001b[0;31m                 \u001b[0;34m'no unique mode; found %d equally common values'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m                 )\n\u001b[1;32m    508\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStatisticsError\u001b[0m: no unique mode; found 2 equally common values"
          ]
        }
      ],
      "source": [
        "tree_ran = id3(xs, ys, features)\n",
        "\n",
        "show(tree_ran)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "FKDAhkcg00LB",
        "outputId": "a38a6595-e61c-4b1b-ee98-74007f5aa6ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now implement a better heuristic (than random) to select the best feature. We implement the one based on the error\n",
        "rate."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ozax4D-R00LB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def select_best_feature(xs, ys, features):\n",
        "    res = None\n",
        "    min_err = None\n",
        "    for feature in features:\n",
        "        err = 0\n",
        "        for value in features[feature]:\n",
        "            xs_value, ys_value = select_data(xs, ys, feature, value)\n",
        "            if ys_value:\n",
        "                y_pred = mode(ys_value)\n",
        "                err += sum([y_pred != y for y in ys])\n",
        "\n",
        "        if min_err is None or err < min_err:\n",
        "            min_err = err\n",
        "            res = feature\n",
        "    return res"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ax8xTjFI00LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run this function on the original dataset and see that the feature it will select is now humidity."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "91PIAwO600LC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "select_best_feature(xs, ys, features)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "I_dTT7f100LC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tree_err = id3(xs, ys, features)\n",
        "show(tree_err)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GGIPIhN000LC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Trees in Scikit-Learn\n",
        "\n",
        "Scikit-learn is a free software machine learning library for Python. It features various classification, regression and\n",
        "clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and\n",
        "is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy. In this notebook you\n",
        "will learn how to use the decision trees implemented in scikit-learn.\n",
        "\n",
        "Before you start, yous should make sure to have scikit-learn installed in your anaconda environment."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "YxCf8gwI00LC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!conda install --yes scikit-learn\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nseoJghM00LC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Dataset\n",
        "\n",
        "In this notebook you will be working with the Iris dataset. The Iris flower data set or Fisher's Iris data set is a\n",
        "multivariate data set introduced by the British statistician, eugenicist, and biologist Ronald Fisher in his 1936 paper:\n",
        "\"The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis\".\n",
        "\n",
        "The iris dataset is a classic and easy multi-class classification dataset. In the following table we find some of the\n",
        "properties of this dataset.\n",
        "\n",
        "| Property | Value |\n",
        "|--|--|\n",
        "| Classes | 3 |\n",
        "| Samples per class | 50 |\n",
        "| Samples total | 150 |\n",
        "| Dimensionality | 4 |\n",
        "| Features | real, positive |\n",
        "\n",
        "Each example contains the measurements of four features of iris plants: the length and the width of the sepals and\n",
        "petals, in centimeters; and, each example is labeled with one of three classes corresponding to one of the iris species:\n",
        "iris setosa, iris virginica and iris versicolor.\n",
        "\n",
        "Scikit-learn provides a set of famous datasets, and the Iris dataset is one of them. To load the Iris dataset we just\n",
        "need to run the function `load_iris`."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "q4OHv20A00LD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "iris.target_names"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "PLR8Q5_g00LD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now define the dataset we will be working with.\n",
        "\n",
        "xs = feature matrix: values relating to the feature\n",
        "\n",
        "ys = target matrix: the quantity we want to predict from the data aka dependent variable"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FFguaEM100LD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris.target"
      ],
      "metadata": {
        "id": "W0RpmYxDgfAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "xs = iris.data\n",
        "ys = iris.target"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3gVvniN200LD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning a Decision Tree\n",
        "\n",
        "Scikit-learn implements a `DecisionTreeClassifier` for classification tasks and a `DecisionTreeRegressor` for regression\n",
        "tasks. In this notebook we will learn to use the `DecisionTreeClassifier`."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VYtNc_X100LE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ekZZ9Y1500LE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A `DecisionTreeClassifier` object takes as input two arrays: an array `xs`, sparse or dense, of shape\n",
        "(n_samples, n_features) holding the training samples, and an array `ys` of integer values, shape (n_samples,),\n",
        "holding the class labels for the training samples.\n",
        "\n",
        "Read more about the property of this class directly from the documentation of scikit-learn following this\n",
        "[link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier).\n",
        "\n",
        "To train this classifier with default parameters you just need to create a `DecisionTreeClassifier` object and invoke\n",
        "the method fit on the training data."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ijNN9Yoq00LE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "toy_xs = [[0, 0], [1, 1]]\n",
        "toy_ys = ['yes', 'no']\n",
        "\n",
        "tree_clf = DecisionTreeClassifier()\n",
        "\n",
        "tree_clf.fit(toy_xs, toy_ys)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UEam5gJr00LE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now use the method predict to test this tree on a new example."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ENJwDRyv00LE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tree_clf.predict([[0, 1]])\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ipaq6cVc00LE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also visualize the tree by using the method `plot_tree`."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "stLfCMvo00LF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "plot_tree(tree_clf)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "F9Qvdg_x00LF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we can see here is that this tree rather than using the Entropy uses the gini index. We can change that by changing\n",
        "the `criterion` parameter of the decision tree.\n",
        "\n",
        "We now train a decision tree on the Iris dataset."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "EKQL8d6m00LF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "tree_clf = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
        "tree_clf.fit(xs, ys)\n",
        "\n",
        "plot_tree(tree_clf, feature_names=iris.feature_names)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mnRtHsPV00LF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Decision Tree\n",
        "\n",
        "To evaluate the performance of the decision tree trained we use the accuracy measure. The accuracy measure tells us\n",
        "what is the proportion of the dataset that has been correctly classified.\n",
        "\n",
        "Follow this\n",
        "[link](https://developers.google.com/machine-learning/crash-course/classification/accuracy)\n",
        "to learn more about this measure."
      ],
      "metadata": {
        "collapsed": false,
        "id": "-Tedrs9200LF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_true=ys, y_pred=tree_clf.predict(xs))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Z6gFLX3q00LG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Boundary\n",
        "\n",
        "In the following we want to visualize the decision boundary of a learned decision tree for the Iris dataset. To make\n",
        "the visualization readable we do this for feature pairs. We select these pairs via\n",
        "the variables `axis_0`, and `axis_1`."
      ],
      "metadata": {
        "collapsed": false,
        "id": "oHqnB5Wi00LG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# let's train a decision tree only on two features\n",
        "axis_0 = 0\n",
        "axis_1 = 1\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
        "tree_clf.fit(xs[:, [axis_0, axis_1]], ys)\n",
        "\n",
        "# create a grid of points to plot the countour\n",
        "x_min, x_max = xs[:, 0].min() - 1, xs[:, 0].max() + 1\n",
        "y_min, y_max = xs[:, 1].min() - 1, xs[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
        "\n",
        "# predict the outcome for the grid of points\n",
        "zz = tree_clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "zz = zz.reshape(xx.shape)\n",
        "cs = plt.contourf(xx, yy, zz, cmap=plt.cm.RdYlBu)\n",
        "\n",
        "# define axis\n",
        "plt.xlabel(iris.feature_names[axis_0])\n",
        "plt.ylabel(iris.feature_names[axis_1])\n",
        "\n",
        "# plot the dataset\n",
        "for i, color, marker in zip(range(3), 'ryb', 'o^s'):\n",
        "    idx = np.where(ys == i)\n",
        "    plt.scatter(xs[idx, axis_0], xs[idx, axis_1], c=color, marker=marker, label=iris.target_names[i],\n",
        "                cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "C7K_1TN600LG"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "decision_trees.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}