{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tommylouistaylor/CEGE0004_MachineLearning/blob/master/3%20-%20Week/instance-based_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instance Based Learning\n",
        "1. Implement k-Nearest Neighbors (kNN) algorithm in Python\n",
        "2. Use kNN and SVN algorithms in scikit-learn."
      ],
      "metadata": {
        "id": "GDJDHjiv18O0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Wine Dataset"
      ],
      "metadata": {
        "id": "yIFbE1-QJ005"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "d-qSBL4QlcVu"
      },
      "source": [
        "### The Wine Dataset\n",
        "\n",
        "Each example from the [Wine dataset](https://archive.ics.uci.edu/ml/datasets/Wine) dataset contains:\n",
        "* 13 attributes (xs) ~ containing quantities of each constituent\n",
        "* 1 class identifier (ys) ~ containing id of the wine type\n",
        "\n",
        "Properties:\n",
        "\n",
        "|Property|Value|\n",
        "|--|--|\n",
        "|Classes|3|\n",
        "|Samples per class|~59|\n",
        "|Samples total|178|\n",
        "|Dimensionality|13|\n",
        "|Features|positive, natural and real|"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read dataset"
      ],
      "metadata": {
        "id": "eNuAr4z96nZe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GiZaPMrVlcVz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.set_printoptions(threshold=np.inf) # print full array\n",
        "%load_ext google.colab.data_table     # print full df\n",
        "\n",
        "# reference data source\n",
        "dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
        "\n",
        "# set col names manually, as no headers.\n",
        "names = ['class', # label\n",
        "         'alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total phenols', 'flavanoids',\n",
        "         'non-flavanoid phenols', 'proanthocyanins', 'color_intensity', 'hue', 'protein_content', 'proline']  # set col names manually, as no header.\n",
        "\n",
        "# read dataset into df\n",
        "df = pd.read_csv(dataset_url, names=names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G3SZ5h6slcV1"
      },
      "outputs": [],
      "source": [
        "# view df\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wxe0ZkEwlcV1"
      },
      "outputs": [],
      "source": [
        "# view summary statitics:\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "aZ6ilXZllcV2"
      },
      "source": [
        "### Preprocessing: Split into Training and Test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "N9JtXK4TlcV2"
      },
      "outputs": [],
      "source": [
        "# randomise first to select unbiased set of examples\n",
        "df = df.sample(frac=1)\n",
        "df.head() # view randomised df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uwljnCw5lcV3"
      },
      "outputs": [],
      "source": [
        "# seperate output target class (ys) from the input feature attributes (xs)\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)          # print numbers with float precision\n",
        "ys, xs = np.split(df.values, [1], axis=1)   # split feature array from target array\n",
        "ys = ys.reshape(-1)                         # *** what does reshaping do here? ***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ScHzaPzqlcV4"
      },
      "outputs": [],
      "source": [
        "# Partition 80% for training and 20% for testing\n",
        "n_train = len(xs) * 80 // 100                         # get count for 80% of the datasets ~ 80% is 142 rows\n",
        "xs_train, xs_test = np.split(xs, [n_train], axis=0)   # xs: 80% into train, remaining 20% into test\n",
        "ys_train, ys_test = np.split(ys, [n_train], axis=0)   # ys: 80% into train, remaining 20% into test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print shape oto ensure split successful (rows, cols)\n",
        "print('feature training set:\\t', xs_train.shape)\n",
        "print('feature test set:\\t', xs_test.shape)\n",
        "print('target training set:\\t', ys_train.shape)\n",
        "print('target test set:\\t', ys_test.shape)"
      ],
      "metadata": {
        "id": "NSJvN1MMAOES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalise Variation in Feature values (xs) to remove Bias"
      ],
      "metadata": {
        "id": "ygrW2XezCctJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "soe-aja5lcV5"
      },
      "outputs": [],
      "source": [
        "# Some attributes (xs) have a wider range (variance) than others\n",
        "# attributes with lesser variance will dominate the Learner's distance function\n",
        "# mitigate bias by deploying normalisation e.g. standardisation (aka z-score)\n",
        "\n",
        "# get normalisation 'hyperparameters' from feature training set ~ value used to control the learning process\n",
        "mu = np.mean(xs_train, axis=0)      # mean\n",
        "sigma = np.std(xs_train, axis=0)    # sd\n",
        "\n",
        "# create normalised version of feature training set using hyperparameters\n",
        "xs_train = (xs_train - mu)/sigma    # creates normalised version of feature training set\n",
        "xs_test = (xs_test - mu)/sigma      # apply same to feature test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test normalisation on training set\n",
        "np.mean(xs_train, axis=0) # vector representing mean per col should show ONLY zero vals"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcktzHLuIGVm",
        "outputId": "ead91c8d-16af-46b6-8bdc-4a29e180f4d6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0., -0.,  0.,  0.,  0.,  0., -0., -0.,  0., -0.,  0., -0., -0.])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test normalisation on test set\n",
        "np.mean(xs_test, axis=0)  # vector representing mean per col should show CLOSE to zero vals"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSMlXulbI4VV",
        "outputId": "c7e551a0-e737-47f3-c4df-b9b1f0cd3f0c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.1806259 , -0.04846662,  0.15877923,  0.29400117, -0.13000536,\n",
              "       -0.17718004, -0.18778424,  0.12808511,  0.05581863,  0.1255761 ,\n",
              "       -0.03218211, -0.13138969, -0.18586769])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qguufThHlcV7"
      },
      "source": [
        "## Implement Nearest Neighbor (NN) Algorithm in Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XmEBTgRvlcV7"
      },
      "outputs": [],
      "source": [
        "class NN: # implement NN from scratch\n",
        "\n",
        "    def __init__(self, distance):\n",
        "        self.training_examples = []\n",
        "        self.distance = distance\n",
        "\n",
        "    def add_example(self, x, y):\n",
        "        \"\"\"\n",
        "        Add one example to the list of training examples.\n",
        "        :param x: The vector of feature values\n",
        "        :param y: The label associated to this example\n",
        "        \"\"\"\n",
        "        self.training_examples.append((x, y))\n",
        "\n",
        "    def add_examples(self, xs, ys):\n",
        "        \"\"\"\n",
        "        Add a list of examples to the list of training examples.\n",
        "        :param xs: A list of vectors of fature values\n",
        "        :param ys: A list of labels associated to the examples\n",
        "        \"\"\"\n",
        "        for x, y in zip(xs, ys):\n",
        "            self.add_example(x, y)\n",
        "\n",
        "    def closest_training_example(self, x_q):\n",
        "        y_closest = None\n",
        "        x_closest = None\n",
        "        min_score = float('inf')\n",
        "        # find closest example\n",
        "        for x, y in self.training_examples:\n",
        "            score = self.distance(x_q, x)\n",
        "            if score < min_score:\n",
        "                min_score = score\n",
        "                x_closest = x\n",
        "                y_closest = y\n",
        "\n",
        "        return x_closest, y_closest\n",
        "\n",
        "    def classify(self, xq):\n",
        "        _, y_hat = self.closest_training_example(xq)\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Wb5sLxlvlcV7"
      },
      "source": [
        "In order to instantiate this classifier we need to define a distance function. Since we are dealing with continuous\n",
        "features we will define the euclidean distance. You are invited to develop and test another distance measure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IsuSiskXlcV8"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(x_1, x_2):\n",
        "    res = 0\n",
        "    for a_1, a_2 in zip(x_1, x_2):\n",
        "        res += (a_1 - a_2) ** 2\n",
        "    res **= 0.5\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tRuampA8lcV8"
      },
      "source": [
        "The euclidean distance of the points (0, 0) and (1, 1) should be $\\sqrt{2}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LG0OLJmklcV8",
        "outputId": "02278482-9c2a-4057-ad75-00b7782cd0cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.euclidean_distance>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "euclidean_distance([0, 0], [1, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ZytH92OFlcV8"
      },
      "source": [
        "We now instantiate the NN classifier and train it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TUwhWqvAlcV8"
      },
      "outputs": [],
      "source": [
        "nn_clf = NN(euclidean_distance)         # make instance of NN class called nn_clf\n",
        "\n",
        "nn_clf.add_examples(xs_train, ys_train) # add feature and target training datasets to NN class method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "kPCeOvUplcV8"
      },
      "source": [
        "To evaluate how this classifier performs on the test set we will measure its accuracy. Note that evaluating the\n",
        "accuracy on the training set is pointless because this will always be 1 by definition. We will now do also this only for\n",
        "instructive purposes.\n",
        "\n",
        "We now define the accuracy measure. Remember that the accuracy is equal to the proportion of examples that the\n",
        "classifier predicted correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uGueSMyylcV9"
      },
      "outputs": [],
      "source": [
        "def accuracy(ys, ys_hat):\n",
        "    res = 0\n",
        "    for y, y_hat in zip(ys, ys_hat):\n",
        "        if y == y_hat:\n",
        "            res += 1\n",
        "    res /= len(ys)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NopGjpxilcV9"
      },
      "source": [
        "We now test the classifier on both training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_5SAa4hplcV9",
        "outputId": "680650c3-7e54-4b0d-c303-879dc2c17761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy of NN 1.0\n",
            "Test accuracy of NN 1.0\n"
          ]
        }
      ],
      "source": [
        "ys_train_pred = []\n",
        "for x in xs_train:\n",
        "    y_hat = nn_clf.classify(x)\n",
        "    ys_train_pred.append(y_hat)\n",
        "\n",
        "ys_test_pred = []\n",
        "for x in xs_test:\n",
        "    y_hat = nn_clf.classify(x)\n",
        "    ys_test_pred.append(y_hat)\n",
        "\n",
        "print('Train accuracy of NN', accuracy(ys_train, ys_train_pred))\n",
        "print('Test accuracy of NN', accuracy(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "omXMExo8lcV9"
      },
      "source": [
        "Let's now compare the test result of this classifier to a random classifier. Is this NN classifier any better?\n",
        "Remember that a random classifier would correctly predict the class one third of the times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TFeCBvW3lcV9",
        "outputId": "9edb8647-c043-4104-9606-d15e8b4d2942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of a random classifier 0.3333333333333333\n"
          ]
        }
      ],
      "source": [
        "ys_test_pred_random = np.random.randint(1, 4, len(ys_test))                             # create random cluster\n",
        "print('Test accuracy of a random classifier', accuracy(ys_test, ys_test_pred_random))   # test accuracy against a random "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7I5K_52VlcV9"
      },
      "source": [
        "Let's have a look at the result of a random classifier by repeating this experiment many times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sQt9CGMalcV-",
        "outputId": "31610fd3-4092-4ef9-ca47-e95659d0ec19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected accuracy of a random classifier 0.33392777777777777\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "accuracies = []\n",
        "for _ in range(10000):\n",
        "    ys_test_pred_random = np.random.randint(1, 4, len(ys_test))\n",
        "    accuracies.append(accuracy(ys_test, ys_test_pred_random))\n",
        "\n",
        "plt.hist(accuracies)\n",
        "plt.show()\n",
        "\n",
        "print('Expected accuracy of a random classifier', np.mean(accuracies))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Lo0n9a4tlcV-"
      },
      "source": [
        "Does this accuracy make sense? Is this accuracy similar to the one you had predicted?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ve3v60ezlcV-"
      },
      "source": [
        "## Implement k-Nearest Neighbor (kNN) Algorithm in Python (extented from NN)\n",
        "\n",
        "We will now extend the NN algorithm to develop the k-Nearest Neighbor (kNN) algorithm.\n",
        "By extending the NN algorithm we avoid repeating the training code. This is in fact the same.\n",
        "In the classification method, in order to avoid the sorting of\n",
        "all the examples after having measured their score, we will make use of priority queues, which allow us to keep track\n",
        "only of the first $k$-nearest examples, making the code more efficient. You are free to implement the version where\n",
        "first all the examples are scored, then sorted and selected. These two versions, if correctly implemented,\n",
        "should produce to the same result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WEmNgn9plcV-"
      },
      "outputs": [],
      "source": [
        "from statistics import mode\n",
        "from heapq import heappush, heappushpop\n",
        "\n",
        "class KNN(NN):\n",
        "\n",
        "    def __init__(self, distance):\n",
        "        super().__init__(distance)\n",
        "\n",
        "    def closest_training_examples(self, x_q, k=1):\n",
        "        k_nearest = []\n",
        "\n",
        "        # initialize an heap with k elements\n",
        "        for x, y  in self.training_examples[:k]:\n",
        "            score = self.distance(x_q, x)\n",
        "            heappush(k_nearest, (-score, (x, y)))\n",
        "\n",
        "        # find the k-nearest example\n",
        "        for x, y in self.training_examples[k:]:\n",
        "            score = self.distance(x_q, x)\n",
        "            heappushpop(k_nearest, (-score, (x, y)))\n",
        "\n",
        "        # we no longer need to keep the score\n",
        "        res = [(x, y) for _, (x, y) in k_nearest]\n",
        "        return res\n",
        "\n",
        "    def classify(self, x_q, k = 1):\n",
        "        # find the k closest\n",
        "        k_nearest_xs, k_nearest_ys = zip(*self.closest_training_examples(x_q, k))\n",
        "        # return the mode\n",
        "        return mode(k_nearest_ys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "sQUvyHNrlcV-"
      },
      "source": [
        "We now train and test this algorithm in the same way we did for the NN algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iFYaZv-5lcV_",
        "outputId": "81f75366-bd48-45a3-9a60-3d5003068b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy of kNN 1.0\n",
            "Test accuracy of kNN 1.0\n"
          ]
        }
      ],
      "source": [
        "knn_clf = KNN(euclidean_distance)\n",
        "\n",
        "knn_clf.add_examples(xs_train, ys_train)\n",
        "\n",
        "ys_train_pred = []\n",
        "for x in xs_train:\n",
        "    y_hat = knn_clf.classify(x)\n",
        "    ys_train_pred.append(y_hat)\n",
        "\n",
        "ys_test_pred = []\n",
        "for x in xs_test:\n",
        "    y_hat = knn_clf.classify(x)\n",
        "    ys_test_pred.append(y_hat)\n",
        "\n",
        "print('Train accuracy of kNN', accuracy(ys_train, ys_train_pred))\n",
        "print('Test accuracy of kNN', accuracy(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "gGd-x5PalcV_"
      },
      "source": [
        "Nothing has changed with respect to the NN algorithm because we have implicitly used $k=1$. Let's now try $k=5$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eMZmX5ddlcV_",
        "outputId": "166ac7db-d82a-436a-c5d6-58efe2d4a52d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy of kNN 0.9647887323943662\n",
            "Test accuracy of kNN 0.9722222222222222\n"
          ]
        }
      ],
      "source": [
        "ys_train_pred = []\n",
        "for x in xs_train:\n",
        "    y_hat = knn_clf.classify(x, 5)\n",
        "    ys_train_pred.append(y_hat)\n",
        "\n",
        "ys_test_pred = []\n",
        "for x in xs_test:\n",
        "    y_hat = knn_clf.classify(x, 5)\n",
        "    ys_test_pred.append(y_hat)\n",
        "\n",
        "\n",
        "print('Train accuracy of kNN', accuracy(ys_train, ys_train_pred))\n",
        "print('Test accuracy of kNN', accuracy(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_m67wzVdlcV_"
      },
      "source": [
        "It seems that considering more points did not help. Note that this time the training accuracy has changed. Can you\n",
        "explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "19nDKPAilcV_"
      },
      "source": [
        "## Implement k-Nearest Neighbor (kNN) Algorithm in Scikit-Learn using SPECIFIC Hyper-Paramaters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "inlG1P2YlcV_"
      },
      "outputs": [],
      "source": [
        "# call the classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean') # pass n_neighbors and metric 'hyper-parameters'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "El2JMroTlcV_"
      },
      "outputs": [],
      "source": [
        "# train the classifier with training datasets\n",
        "knn_clf.fit(xs_train, ys_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QQShe3IulcWA"
      },
      "outputs": [],
      "source": [
        "# predict class (ys~wine type) using classifier\n",
        "ys_test_pred = knn_clf.predict(xs_test)\n",
        "ys_test_pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the result of classifier by performing an accuracy test\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(ys_test, ys_test_pred)  # compare predicted classes against true classes\n",
        "print('Test accuracy of kNN', accuracy)           # 1=accuracy, 0=not accurate"
      ],
      "metadata": {
        "id": "EG9_AmbwUkyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement k-Nearest Neighbor (kNN) Algorithm in Scikit-Learn using OPTIMUM Hyper-Paramaters\n",
        "Overtuning the hyper-parameters (e.g. n-neighbors, metric) when training the classifier can lead to overfitting on the test set ~ aka classifier learns the 'noise' of the training set too well and becomes less effective when applied to the test set. Using k-fold cross-validation to find the optimum hyper-paramaters will ensure the accuracy measured on the test set is representitive of what is expected on unseen examples."
      ],
      "metadata": {
        "id": "cQQUQbU4j1zF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "md5xLrJJlcWA"
      },
      "outputs": [],
      "source": [
        "# firstly confirm that retuning the hyper-parameters will change the outcome\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=1, metric='cosine')        # call classifier and specify cosine metric\n",
        "knn_clf.fit(xs_train, ys_train)                                       # train classifier with dataset\n",
        "ys_test_pred = knn_clf.predict(xs_test)                               # predict the classes using the trained classifer\n",
        "print('Test accuracy of kNN', accuracy_score(ys_test, ys_test_pred))  # test accuracy of result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "g7uL8T8PlcWA"
      },
      "outputs": [],
      "source": [
        "# specify a set of hyperparameters to explore\n",
        "param_grid = [{\n",
        "  'weights': [\"uniform\", \"distance\"],\n",
        "  'n_neighbors': range(1, 11),\n",
        "  'metric':['euclidean', 'manhattan', 'cosine']}]\n",
        "\n",
        "# find best combination of hyperparameters using K-fold cross-validation\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "knn_clf = KNeighborsClassifier()                                      # call kNN classifier WITHOUT specifying params\n",
        "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=2)      # loop through ALL predefined params using GridSearchCV\n",
        "grid_search.fit(xs_train, ys_train)                                   # fit ALL learners onto the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GcHwgoSBlcWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f301e0-4115-4ad5-dfcd-e498a9fd6f9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(metric='manhattan', n_neighbors=3)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# best hyper-parameters found by cross-validation\n",
        "best_estimator = grid_search.best_estimator_\n",
        "best_estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eJOPb8ROlcWB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "9af16ebc-4a12-425d-c827-2d52ed0256ab"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-e7b733574127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# evaluate result accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#print('Train accuracy of kNN', accuracy(ys_train, ys_train_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#print('Test accuracy of kNN', accuracy(ys_test, ys_test_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
          ]
        }
      ],
      "source": [
        "# call classifier using optimum hyper-parameters\n",
        "knn_clf = best_estimator\n",
        "\n",
        "# train classifier with training set\n",
        "knn_clf.fit(xs_train, ys_train)           \n",
        "\n",
        "# predict class using classifier\n",
        "ys_train_pred_ = knn_clf.predict(xs_train)\n",
        "ys_test_pred_ = knn_clf.predict(xs_test)\n",
        "\n",
        "# evaluate result accuracy\n",
        "accuracy(ys_test, ys_test_pred)\n",
        "#print('Train accuracy of kNN', accuracy(ys_train, ys_train_pred))\n",
        "#print('Test accuracy of kNN', accuracy(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "b7K2FaPzlcWB"
      },
      "source": [
        "## Implement Support Vector Machines (SVM) in Scikit-Learn using SPECIFIC hyper-parameters\n",
        "\n",
        "Note how we are setting the $C$ hyper-parameter of SVM. $C$ controls the trade-off between having a small and strict\n",
        "margin and a wider and loose margin. Following we will set $C$ to infinity which makes the margin infinitely strict.\n",
        "This means that based on the dataset, the fitting of the SVM may fail if the training algorithm fails to separate all\n",
        "the training examples perfectly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CCbrwD5ZlcWB"
      },
      "outputs": [],
      "source": [
        "# call classifier and set hyper-parameters\n",
        "from sklearn.svm import SVC\n",
        "svm_clf = SVC(kernel=\"linear\", C=float(\"inf\")) # C controls trade-off between small-strict margin and wide-loose margin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3K9JCsY7lcWB"
      },
      "outputs": [],
      "source": [
        "# train classifier using training set\n",
        "svm_clf.fit(xs_train, ys_train) # SVM training algorithm fits the training examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JhI4grFwlcWC"
      },
      "outputs": [],
      "source": [
        "# predict class using classifier\n",
        "ys_train_pred = svm_clf.predict(xs_train)\n",
        "ys_test_pred = svm_clf.predict(xs_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate result\n",
        "print('Train accuracy of SVM', accuracy(ys_train, ys_train_pred))\n",
        "print('Test accuracy of SVM', accuracy(ys_test, ys_test_pred))"
      ],
      "metadata": {
        "id": "lY3BhiK8v9XS",
        "outputId": "2e174818-d821-4015-dabe-b3dccaf17a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-9bf216f0ea28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train accuracy of SVM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_train_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy of SVM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "lFv2XO97lcWC"
      },
      "source": [
        "How would you find the best hyper-parameter C value? Try re-implement the code used to validate the kNN\n",
        "classifier above."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "instance-based_learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}