{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tommylouistaylor/CEGE0004/blob/master/3%20-%20Week/instance-based_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "d-qSBL4QlcVu"
      },
      "source": [
        "# Instance Based Learning\n",
        "\n",
        "In this notebook you will learn how to implement the k-Nearest Neighbors (kNN) algorithm in Python and learn how to\n",
        "use kNN and SVN algorithms in scikit-learn.\n",
        "\n",
        "## The Dataset\n",
        "\n",
        "In this notebook you will be working with the [Wine dataset](https://archive.ics.uci.edu/ml/datasets/Wine).\n",
        "This dataset is the result of a chemical analysis of wines\n",
        "grown in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents\n",
        "found in each of the three types of wines.\n",
        "\n",
        "This is a good dataset for testing classifiers. In the following table we find some properties of this dataset.\n",
        "\n",
        "|Property|Value|\n",
        "|--|--|\n",
        "|Classes|3|\n",
        "|Samples per class|~59|\n",
        "|Samples total|178|\n",
        "|Dimensionality|13|\n",
        "|Features|positive, natural and real|\n",
        "\n",
        "Each example contains a class identifier and 13 attributes representing the outcome of the analysis performed on the\n",
        "wine samples.\n",
        "\n",
        "We will download this dataset directly from the UCI repository using Pandas. Note that this dataset does not have a\n",
        "header which means that we need to provide the column names manually. This header comes from reading the content of this\n",
        "[file](https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.names)\n",
        "(you can open this file with a text editor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GiZaPMrVlcVz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
        "\n",
        "names = ['class', # label\n",
        "         'alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total phenols', 'flavanoids',\n",
        "         'non-flavanoid phenols', 'proanthocyanins', 'color_intensity', 'hue', 'protein_content', 'proline']\n",
        "\n",
        "df = pd.read_csv(dataset_url, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uNRxNKUblcV0"
      },
      "source": [
        "Let's first have a look at the content of this dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G3SZ5h6slcV1"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "rZExI0tylcV1"
      },
      "source": [
        "Let's also have a look at some statistics of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "wxe0ZkEwlcV1",
        "outputId": "dfec41d5-fe85-4b6b-c254-04a2cb0fa8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d21dd62c-9f72-4514-bb5c-1b2fbb63c6da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>non-flavanoid phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>protein_content</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.938202</td>\n",
              "      <td>13.000618</td>\n",
              "      <td>2.336348</td>\n",
              "      <td>2.366517</td>\n",
              "      <td>19.494944</td>\n",
              "      <td>99.741573</td>\n",
              "      <td>2.295112</td>\n",
              "      <td>2.029270</td>\n",
              "      <td>0.361854</td>\n",
              "      <td>1.590899</td>\n",
              "      <td>5.058090</td>\n",
              "      <td>0.957449</td>\n",
              "      <td>2.611685</td>\n",
              "      <td>746.893258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.775035</td>\n",
              "      <td>0.811827</td>\n",
              "      <td>1.117146</td>\n",
              "      <td>0.274344</td>\n",
              "      <td>3.339564</td>\n",
              "      <td>14.282484</td>\n",
              "      <td>0.625851</td>\n",
              "      <td>0.998859</td>\n",
              "      <td>0.124453</td>\n",
              "      <td>0.572359</td>\n",
              "      <td>2.318286</td>\n",
              "      <td>0.228572</td>\n",
              "      <td>0.709990</td>\n",
              "      <td>314.907474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.030000</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>278.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.362500</td>\n",
              "      <td>1.602500</td>\n",
              "      <td>2.210000</td>\n",
              "      <td>17.200000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>1.742500</td>\n",
              "      <td>1.205000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>3.220000</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>1.937500</td>\n",
              "      <td>500.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>13.050000</td>\n",
              "      <td>1.865000</td>\n",
              "      <td>2.360000</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>2.355000</td>\n",
              "      <td>2.135000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>1.555000</td>\n",
              "      <td>4.690000</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>2.780000</td>\n",
              "      <td>673.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>13.677500</td>\n",
              "      <td>3.082500</td>\n",
              "      <td>2.557500</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>2.875000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.950000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.120000</td>\n",
              "      <td>3.170000</td>\n",
              "      <td>985.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>14.830000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.230000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>3.880000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>3.580000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1680.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d21dd62c-9f72-4514-bb5c-1b2fbb63c6da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d21dd62c-9f72-4514-bb5c-1b2fbb63c6da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d21dd62c-9f72-4514-bb5c-1b2fbb63c6da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            class     alcohol  ...  protein_content      proline\n",
              "count  178.000000  178.000000  ...       178.000000   178.000000\n",
              "mean     1.938202   13.000618  ...         2.611685   746.893258\n",
              "std      0.775035    0.811827  ...         0.709990   314.907474\n",
              "min      1.000000   11.030000  ...         1.270000   278.000000\n",
              "25%      1.000000   12.362500  ...         1.937500   500.500000\n",
              "50%      2.000000   13.050000  ...         2.780000   673.500000\n",
              "75%      3.000000   13.677500  ...         3.170000   985.000000\n",
              "max      3.000000   14.830000  ...         4.000000  1680.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "aZ6ilXZllcV2"
      },
      "source": [
        "## Preprocessing the Dataset\n",
        "\n",
        "This dataset will require some preprocessing. First, since we would like to test how any of the learning algorithms\n",
        "used later perform on unseen data. We split the dataset into a training set and a test set.\n",
        "\n",
        "* training set — a subset to train a model\n",
        "\n",
        "* test set — a subset to test the trained model\n",
        "\n",
        "\n",
        "To do this we first randomize the data. We do this in order to make sure to select an unbiased set of examples\n",
        "for the test set. Notice that in this case the training is sorted based on the target `class`, which makes the\n",
        "initial randomization necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "N9JtXK4TlcV2",
        "outputId": "57a2e934-c00a-4afa-f05f-28f7ba72c7de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-354a5270-11d7-4772-99c2-61d2bebbf69d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>non-flavanoid phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>protein_content</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>13.64</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.56</td>\n",
              "      <td>15.2</td>\n",
              "      <td>116</td>\n",
              "      <td>2.70</td>\n",
              "      <td>3.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.66</td>\n",
              "      <td>5.10</td>\n",
              "      <td>0.96</td>\n",
              "      <td>3.36</td>\n",
              "      <td>845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>2</td>\n",
              "      <td>12.37</td>\n",
              "      <td>1.63</td>\n",
              "      <td>2.30</td>\n",
              "      <td>24.5</td>\n",
              "      <td>88</td>\n",
              "      <td>2.22</td>\n",
              "      <td>2.45</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.90</td>\n",
              "      <td>2.12</td>\n",
              "      <td>0.89</td>\n",
              "      <td>2.78</td>\n",
              "      <td>342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>2</td>\n",
              "      <td>12.17</td>\n",
              "      <td>1.45</td>\n",
              "      <td>2.53</td>\n",
              "      <td>19.0</td>\n",
              "      <td>104</td>\n",
              "      <td>1.89</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.45</td>\n",
              "      <td>1.03</td>\n",
              "      <td>2.95</td>\n",
              "      <td>1.45</td>\n",
              "      <td>2.23</td>\n",
              "      <td>355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>3</td>\n",
              "      <td>13.32</td>\n",
              "      <td>3.24</td>\n",
              "      <td>2.38</td>\n",
              "      <td>21.5</td>\n",
              "      <td>92</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.45</td>\n",
              "      <td>1.25</td>\n",
              "      <td>8.42</td>\n",
              "      <td>0.55</td>\n",
              "      <td>1.62</td>\n",
              "      <td>650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>2</td>\n",
              "      <td>12.00</td>\n",
              "      <td>3.43</td>\n",
              "      <td>2.00</td>\n",
              "      <td>19.0</td>\n",
              "      <td>87</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.64</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.87</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0.93</td>\n",
              "      <td>3.05</td>\n",
              "      <td>564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-354a5270-11d7-4772-99c2-61d2bebbf69d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-354a5270-11d7-4772-99c2-61d2bebbf69d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-354a5270-11d7-4772-99c2-61d2bebbf69d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     class  alcohol  malic_acid  ...   hue  protein_content  proline\n",
              "19       1    13.64        3.10  ...  0.96             3.36      845\n",
              "128      2    12.37        1.63  ...  0.89             2.78      342\n",
              "64       2    12.17        1.45  ...  1.45             2.23      355\n",
              "148      3    13.32        3.24  ...  0.55             1.62      650\n",
              "119      2    12.00        3.43  ...  0.93             3.05      564\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = df.sample(frac=1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "J5Ao0GyClcV3"
      },
      "source": [
        "We now separate the target `class` from the rest of the attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uwljnCw5lcV3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(suppress=True)          # sets numpy to print numbers with float precision\n",
        "\n",
        "ys, xs = np.split(df.values, [1], axis=1)   # split feature array from target array\n",
        "ys = ys.reshape(-1)                         # what does reshaping do here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5lhH27sqlcV4"
      },
      "source": [
        "And select 80% of the dataset for training and 20% for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ScHzaPzqlcV4",
        "outputId": "b59bbf8d-d9bd-44c6-cae0-3390e2ba54fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set shape:\t (142, 13)\n",
            "test set shape:\t\t (36, 13)\n"
          ]
        }
      ],
      "source": [
        "n_train = len(xs) * 80 // 100                         # find length of dataset in rows\n",
        "xs_train, xs_test = np.split(xs, [n_train], axis=0)   # specify train and test for FEATURES\n",
        "ys_train, ys_test = np.split(ys, [n_train], axis=0)   # specify train and test for TARGET\n",
        "\n",
        "print('training set shape:\\t', xs_train.shape)        # what does 'shape' do here?\n",
        "print('test set shape:\\t\\t', xs_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nTbQYkbOlcV5"
      },
      "source": [
        "Now, we note that attribute values span across various ranges: Some attributes have a much wider range than others.\n",
        "Since the learning algorithms that we will be using later are based on some form of distance function,\n",
        "this variance in the ranges of the attributes may bias the learning algorithm towards examples that look closer in\n",
        "dimensions with a wider range because those attributes will dominate the distance functions.\n",
        "In order to mitigate this bias we perform a normalization across the features. In this case we will perform a\n",
        "standardization (aka Z-score):\n",
        "\n",
        "\\begin{equation}\n",
        "z = \\frac{x-\\mu}{\\sigma}\n",
        "\\end{equation}\n",
        "\n",
        "Any other normalization that achieves a similar result is also fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "soe-aja5lcV5"
      },
      "outputs": [],
      "source": [
        "mu = np.mean(xs_train, axis=0)      # find mean of feature training set\n",
        "sigma = np.std(xs_train, axis=0)    # find sd of feature training set\n",
        "\n",
        "xs_train = (xs_train - mu)/sigma    # creates normalised version of feature training set\n",
        "xs_test = (xs_test - mu)/sigma      # applied the same normalisation to the feature test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pnsIILU3lcV6"
      },
      "source": [
        "Note that the normalization should be computed on the training set and not on the original dataset. This in order to\n",
        "better simulate unseen data. The normalization, together with any preprocessing step that involves statistics over\n",
        "the dataset, should also be considered as belonging to the hyper-parameters of the learning algorithm.\n",
        "\n",
        "After having performed the normalization, if we now compute the mean of the preprocessed training set, we should see\n",
        "that now this mean vector contains only zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9hsHL4HdlcV6",
        "outputId": "f38473ca-ec61-4ca6-bf01-79358b071848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.,  0., -0.,  0., -0.,  0.,  0., -0., -0.,  0.,  0., -0.,  0.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "np.mean(xs_train, axis=0)           # means of zeros show successful normalisation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ubdCS_ihlcV6"
      },
      "source": [
        "If we have properly sampled the dataset, we should get a mean vector for the test set that contains close to zero\n",
        "values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "W4DDkoFvlcV7",
        "outputId": "d3c6224f-002d-44cf-ec79-7b8117bbf772",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0644524 , -0.29714519, -0.05209309, -0.16624847, -0.13175362,\n",
              "        0.21412577,  0.10545937,  0.2871267 ,  0.15551501, -0.0182565 ,\n",
              "        0.13912239, -0.03398166,  0.29890581])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "np.mean(xs_test, axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qguufThHlcV7"
      },
      "source": [
        "## The Nearest Neighbor Algorithm\n",
        "\n",
        "We will now implement the Nearest Neighbor (NN) algorithm in Python from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XmEBTgRvlcV7"
      },
      "outputs": [],
      "source": [
        "class NN: # implement NN from scratch\n",
        "\n",
        "    def __init__(self, distance):\n",
        "        self.training_examples = []\n",
        "        self.distance = distance\n",
        "\n",
        "    def add_example(self, x, y):\n",
        "        \"\"\"\n",
        "        Add one example to the list of training examples.\n",
        "        :param x: The vector of feature values\n",
        "        :param y: The label associated to this example\n",
        "        \"\"\"\n",
        "        self.training_examples.append((x, y))\n",
        "\n",
        "    def add_examples(self, xs, ys):\n",
        "        \"\"\"\n",
        "        Add a list of examples to the list of training examples.\n",
        "        :param xs: A list of vectors of fature values\n",
        "        :param ys: A list of labels associated to the examples\n",
        "        \"\"\"\n",
        "        for x, y in zip(xs, ys):\n",
        "            self.add_example(x, y)\n",
        "\n",
        "    def closest_training_example(self, x_q):\n",
        "        y_closest = None\n",
        "        x_closest = None\n",
        "        min_score = float('inf')\n",
        "        # find closest example\n",
        "        for x, y in self.training_examples:\n",
        "            score = self.distance(x_q, x)\n",
        "            if score < min_score:\n",
        "                min_score = score\n",
        "                x_closest = x\n",
        "                y_closest = y\n",
        "\n",
        "        return x_closest, y_closest\n",
        "\n",
        "    def classify(self, xq):\n",
        "        _, y_hat = self.closest_training_example(xq)\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Wb5sLxlvlcV7"
      },
      "source": [
        "In order to instantiate this classifier we need to define a distance function. Since we are dealing with continuous\n",
        "features we will define the euclidean distance. You are invited to develop and test another distance measure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IsuSiskXlcV8"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(x_1, x_2):\n",
        "    res = 0\n",
        "    for a_1, a_2 in zip(x_1, x_2):\n",
        "        res += (a_1 - a_2) ** 2\n",
        "    res **= 0.5\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "tRuampA8lcV8"
      },
      "source": [
        "The euclidean distance of the points (0, 0) and (1, 1) should be $\\sqrt{2}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "LG0OLJmklcV8",
        "outputId": "02278482-9c2a-4057-ad75-00b7782cd0cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.euclidean_distance>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "euclidean_distance([0, 0], [1, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ZytH92OFlcV8"
      },
      "source": [
        "We now instantiate the NN classifier and train it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TUwhWqvAlcV8"
      },
      "outputs": [],
      "source": [
        "nn_clf = NN(euclidean_distance)         # make instance of NN class called nn_clf\n",
        "\n",
        "nn_clf.add_examples(xs_train, ys_train) # add feature and target training datasets to NN class method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "kPCeOvUplcV8"
      },
      "source": [
        "To evaluate how this classifier performs on the test set we will measure its accuracy. Note that evaluating the\n",
        "accuracy on the training set is pointless because this will always be 1 by definition. We will now do also this only for\n",
        "instructive purposes.\n",
        "\n",
        "We now define the accuracy measure. Remember that the accuracy is equal to the proportion of examples that the\n",
        "classifier predicted correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uGueSMyylcV9"
      },
      "outputs": [],
      "source": [
        "def accuracy(ys, ys_hat):\n",
        "    res = 0\n",
        "    for y, y_hat in zip(ys, ys_hat):\n",
        "        if y == y_hat:\n",
        "            res += 1\n",
        "    res /= len(ys)\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NopGjpxilcV9"
      },
      "source": [
        "We now test the classifier on both training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_5SAa4hplcV9",
        "outputId": "680650c3-7e54-4b0d-c303-879dc2c17761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy of NN 1.0\n",
            "Test accuracy of NN 1.0\n"
          ]
        }
      ],
      "source": [
        "ys_train_pred = []\n",
        "for x in xs_train:\n",
        "    y_hat = nn_clf.classify(x)\n",
        "    ys_train_pred.append(y_hat)\n",
        "\n",
        "ys_test_pred = []\n",
        "for x in xs_test:\n",
        "    y_hat = nn_clf.classify(x)\n",
        "    ys_test_pred.append(y_hat)\n",
        "\n",
        "print('Train accuracy of NN', accuracy(ys_train, ys_train_pred))\n",
        "print('Test accuracy of NN', accuracy(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "omXMExo8lcV9"
      },
      "source": [
        "Let's now compare the test result of this classifier to a random classifier. Is this NN classifier any better?\n",
        "Remember that a random classifier would correctly predict the class one third of the times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TFeCBvW3lcV9",
        "outputId": "9edb8647-c043-4104-9606-d15e8b4d2942",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy of a random classifier 0.3333333333333333\n"
          ]
        }
      ],
      "source": [
        "ys_test_pred_random = np.random.randint(1, 4, len(ys_test))                             # create random cluster\n",
        "print('Test accuracy of a random classifier', accuracy(ys_test, ys_test_pred_random))   # test accuracy against a random "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7I5K_52VlcV9"
      },
      "source": [
        "Let's have a look at the result of a random classifier by repeating this experiment many times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sQt9CGMalcV-",
        "outputId": "31610fd3-4092-4ef9-ca47-e95659d0ec19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected accuracy of a random classifier 0.33392777777777777\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "accuracies = []\n",
        "for _ in range(10000):\n",
        "    ys_test_pred_random = np.random.randint(1, 4, len(ys_test))\n",
        "    accuracies.append(accuracy(ys_test, ys_test_pred_random))\n",
        "\n",
        "plt.hist(accuracies)\n",
        "plt.show()\n",
        "\n",
        "print('Expected accuracy of a random classifier', np.mean(accuracies))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Lo0n9a4tlcV-"
      },
      "source": [
        "Does this accuracy make sense? Is this accuracy similar to the one you had predicted?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ve3v60ezlcV-"
      },
      "source": [
        "# The k-Nearest Neighbor Algorithm\n",
        "\n",
        "We will now extend the NN algorithm to develop the k-Nearest Neighbor (kNN) algorithm.\n",
        "By extending the NN algorithm we avoid repeating the training code. This is in fact the same.\n",
        "In the classification method, in order to avoid the sorting of\n",
        "all the examples after having measured their score, we will make use of priority queues, which allow us to keep track\n",
        "only of the first $k$-nearest examples, making the code more efficient. You are free to implement the version where\n",
        "first all the examples are scored, then sorted and selected. These two versions, if correctly implemented,\n",
        "should produce to the same result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "WEmNgn9plcV-"
      },
      "outputs": [],
      "source": [
        "from statistics import mode\n",
        "from heapq import heappush, heappushpop\n",
        "\n",
        "class KNN(NN):\n",
        "\n",
        "    def __init__(self, distance):\n",
        "        super().__init__(distance)\n",
        "\n",
        "    def closest_training_examples(self, x_q, k=1):\n",
        "        k_nearest = []\n",
        "\n",
        "        # initialize an heap with k elements\n",
        "        for x, y  in self.training_examples[:k]:\n",
        "            score = self.distance(x_q, x)\n",
        "            heappush(k_nearest, (-score, (x, y)))\n",
        "\n",
        "        # find the k-nearest example\n",
        "        for x, y in self.training_examples[k:]:\n",
        "            score = self.distance(x_q, x)\n",
        "            heappushpop(k_nearest, (-score, (x, y)))\n",
        "\n",
        "        # we no longer need to keep the score\n",
        "        res = [(x, y) for _, (x, y) in k_nearest]\n",
        "        return res\n",
        "\n",
        "    def classify(self, x_q, k = 1):\n",
        "        # find the k closest\n",
        "        k_nearest_xs, k_nearest_ys = zip(*self.closest_training_examples(x_q, k))\n",
        "        # return the mode\n",
        "        return mode(k_nearest_ys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "sQUvyHNrlcV-"
      },
      "source": [
        "We now train and test this algorithm in the same way we did for the NN algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "iFYaZv-5lcV_",
        "outputId": "81f75366-bd48-45a3-9a60-3d5003068b15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy of kNN 1.0\n",
            "Test accuracy of kNN 1.0\n"
          ]
        }
      ],
      "source": [
        "knn_clf = KNN(euclidean_distance)\n",
        "\n",
        "knn_clf.add_examples(xs_train, ys_train)\n",
        "\n",
        "ys_train_pred = []\n",
        "for x in xs_train:\n",
        "    y_hat = knn_clf.classify(x)\n",
        "    ys_train_pred.append(y_hat)\n",
        "\n",
        "ys_test_pred = []\n",
        "for x in xs_test:\n",
        "    y_hat = knn_clf.classify(x)\n",
        "    ys_test_pred.append(y_hat)\n",
        "\n",
        "print('Train accuracy of kNN', accuracy(ys_train, ys_train_pred))\n",
        "print('Test accuracy of kNN', accuracy(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "gGd-x5PalcV_"
      },
      "source": [
        "Nothing has changed with respect to the NN algorithm because we have implicitly used $k=1$. Let's now try $k=5$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eMZmX5ddlcV_",
        "outputId": "166ac7db-d82a-436a-c5d6-58efe2d4a52d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy of kNN 0.9647887323943662\n",
            "Test accuracy of kNN 0.9722222222222222\n"
          ]
        }
      ],
      "source": [
        "ys_train_pred = []\n",
        "for x in xs_train:\n",
        "    y_hat = knn_clf.classify(x, 5)\n",
        "    ys_train_pred.append(y_hat)\n",
        "\n",
        "ys_test_pred = []\n",
        "for x in xs_test:\n",
        "    y_hat = knn_clf.classify(x, 5)\n",
        "    ys_test_pred.append(y_hat)\n",
        "\n",
        "\n",
        "print('Train accuracy of kNN', accuracy(ys_train, ys_train_pred))\n",
        "print('Test accuracy of kNN', accuracy(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_m67wzVdlcV_"
      },
      "source": [
        "It seems that considering more points did not help. Note that this time the training accuracy has changed. Can you\n",
        "explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "19nDKPAilcV_"
      },
      "source": [
        "## kNN in Scikit-Learn\n",
        "\n",
        "We will now learn how to use the kNN implementation of scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "inlG1P2YlcV_"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ep76B9RllcV_"
      },
      "source": [
        "To train the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "El2JMroTlcV_"
      },
      "outputs": [],
      "source": [
        "knn_clf.fit(xs_train, ys_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "S7zGCkM5lcWA"
      },
      "source": [
        "We now evaluate the result of this classifier. Here, we should not see any\n",
        "difference with respect to the results obtained above with our implementation of the kNN algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QQShe3IulcWA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ys_test_pred = knn_clf.predict(xs_test)\n",
        "\n",
        "print('Test accuracy of kNN', accuracy_score(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "b4pSvBL9lcWA"
      },
      "source": [
        "Let's now try the cosine distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "md5xLrJJlcWA"
      },
      "outputs": [],
      "source": [
        "knn_clf = KNeighborsClassifier(n_neighbors=1, metric='cosine')\n",
        "\n",
        "knn_clf.fit(xs_train, ys_train)\n",
        "\n",
        "ys_test_pred = knn_clf.predict(xs_test)\n",
        "\n",
        "print('Test accuracy of kNN', accuracy_score(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "TvYU3MERlcWA"
      },
      "source": [
        "Try other $n$ values. Can you find a better one? The danger of doing this hyper-parameter exploration using the test set is\n",
        "that we may overfit these hyper-parameters on the test set.\n",
        "To avoid this, it is better to find the best hyper-parameter values via a validation strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "MfvT-mQ0lcWA"
      },
      "source": [
        "To find these hyper-parameter values we can exploit the grid search of scikit-learn. This will perform a k-fold\n",
        "cross-validation on the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "g7uL8T8PlcWA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [{\n",
        "    'weights': [\"uniform\", \"distance\"],\n",
        "    'n_neighbors': range(1, 11),\n",
        "    'metric':['euclidean', 'manhattan', 'cosine']}]\n",
        "\n",
        "knn_clf = KNeighborsClassifier()\n",
        "grid_search = GridSearchCV(knn_clf, param_grid, cv=5, verbose=2)\n",
        "grid_search.fit(xs_train, ys_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zFHzTIMblcWB"
      },
      "source": [
        "We can now see what are the best hyper-parameter values found by the cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GcHwgoSBlcWB"
      },
      "outputs": [],
      "source": [
        "grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_1HtjhL6lcWB"
      },
      "source": [
        "Let's now try this hyper-parameters on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eJOPb8ROlcWB"
      },
      "outputs": [],
      "source": [
        "knn_clf = KNeighborsClassifier(metric='cosine', n_neighbors=4, weights='distance')\n",
        "\n",
        "knn_clf.fit(xs_train, ys_train)\n",
        "\n",
        "ys_train_pred = knn_clf.predict(xs_train)\n",
        "ys_test_pred = knn_clf.predict(xs_test)\n",
        "\n",
        "print('Train accuracy of kNN', accuracy(ys_train, ys_train_pred))\n",
        "print('Test accuracy of kNN', accuracy(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "mBizUB50lcWB"
      },
      "source": [
        "The accuracy measured on the test set is now a better estimate of the accuracy we would expect on unseen examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "b7K2FaPzlcWB"
      },
      "source": [
        "# Support Vector Machines\n",
        "\n",
        "Here I will introduce you how to use the Support Vector Machine (SVM) implementation of scikit-learn.\n",
        "\n",
        "Note how we are setting the $C$ hyper-parameter of SVM. $C$ controls the trade-off between having a small and strict\n",
        "margin and a wider and loose margin. Following we will set $C$ to infinity which makes the margin infinitely strict.\n",
        "This means that based on the dataset, the fitting of the SVM may fail if the training algorithm fails to separate all\n",
        "the training examples perfectly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "CCbrwD5ZlcWB"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_clf = SVC(kernel=\"linear\", C=float(\"inf\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_npKPAwNlcWB"
      },
      "source": [
        "We now train this classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3K9JCsY7lcWB"
      },
      "outputs": [],
      "source": [
        "svm_clf.fit(xs_train, ys_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1mO_2p9flcWC"
      },
      "source": [
        "The training went well, which means that the SVM training algorithm managed to perfectly fit the training examples.\n",
        "We can now verify this on the training set. We will also test the performance of this classifier on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JhI4grFwlcWC"
      },
      "outputs": [],
      "source": [
        "ys_train_pred = svm_clf.predict(xs_train)\n",
        "ys_test_pred = svm_clf.predict(xs_test)\n",
        "\n",
        "print('Train accuracy of SVM', accuracy(ys_train, ys_train_pred))\n",
        "print('Test accuracy of SVM', accuracy(ys_test, ys_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "lFv2XO97lcWC"
      },
      "source": [
        "How would you find the best hyper-parameter C value? Try re-implement the code used to validate the kNN\n",
        "classifier above."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "instance-based_learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}